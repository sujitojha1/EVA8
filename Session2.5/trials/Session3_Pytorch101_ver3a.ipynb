{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session3_Pytorch101_ver2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NLP-END3/Session3/blob/main/Session3_Pytorch101_ver3a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlfIN84bZf70"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bxydVRloBpO"
      },
      "source": [
        "## 1. Problem Statement\n",
        "\n",
        "Write a neural network that can:\n",
        "\n",
        "1. take 2 inputs:\n",
        "    - an image from the MNIST dataset (say 5), and\n",
        "    - a random number between 0 and 9, (say 7)\n",
        "2. and gives two outputs:\n",
        "    - the \"number\" that was represented by the MNIST image (predict 5), and\n",
        "    - the \"sum\" of this number with the random number and the input image to the network (predict 5 + 7 = 12)\n",
        "3. you can mix fully connected layers and convolution layers\n",
        "4. you can use one-hot encoding to represent the random number input as well as the \"summed\" output.  \n",
        "    a. Random number (7) can be represented as 0 0 0 0 0 0 0 1 0 0  \n",
        "    b. Sum (13) can be represented as: 1. 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0  \n",
        "    c. 0b1101 (remember that 4 digits in binary can at max represent 15, so we may need to go for 5 digits. i.e. 10010  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCYKM8CvKPwH"
      },
      "source": [
        "## 2. Importing required libraries & Checking GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEdgomGU6sBv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "0dfc752e-e298-4d4e-b14c-4857be342c59"
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "print(torch.cuda.is_available())  # Checks if GPU is available\n",
        "print(torch.cuda.get_device_name(0)) # Name of GPU\n",
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-78b75f3db7a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Checks if GPU is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Name of GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \"\"\"\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0m_CudaDeviceProperties\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproperties\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wXPpzP9X-Db"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/mnist_experiment_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGpC3QGI7NJU"
      },
      "source": [
        "## 3. Importing MNIST dataset from pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l4RLz-c7MOm"
      },
      "source": [
        "transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "mnist_train = datasets.MNIST('../data',train=True,download=True) # Train dataset\n",
        "mnist_test = datasets.MNIST('./data',train=False,download=True) # Test dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjmKTyJOLrAv"
      },
      "source": [
        "## 3. Plotting few samples of the downloaded data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3AX1A3jLqV8"
      },
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 10, 10\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(mnist_train), size=(1,)).item()\n",
        "    img, label = mnist_train[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "figure.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhFULDhUmDqT"
      },
      "source": [
        "#dir(mnist_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KWhT4kdbOmn"
      },
      "source": [
        "## 4. Checking the size of the image, label and image information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvo-DfNHJbAb"
      },
      "source": [
        "print(f'Number of examples in training dataset :{len(mnist_train)}')\n",
        "print(f'Shape of the training dataset - images : {mnist_train.data.shape}')\n",
        "print(f'Labels in the training dataset : {mnist_train.targets}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOllBGyqG51"
      },
      "source": [
        "## 5. Defining Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIYJtv69qGmG"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from random import randrange\n",
        "\n",
        "# Dataset is there to be able to interact with DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, inpDataset, transform):\n",
        "    self.inpDataset = inpDataset\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    randomNumber = randrange(10)\n",
        "    sample_image, label = self.inpDataset[index]\n",
        "    if self.transform:\n",
        "        sample_image = self.transform(sample_image)\n",
        "\n",
        "    sample = (sample_image,F.one_hot(torch.tensor(randomNumber),num_classes=10), label,label+randomNumber)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.inpDataset)\n",
        "\n",
        "myData_train = MyDataset(mnist_train,transform) \n",
        "myData_test = MyDataset(mnist_test,transform) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrlc9naOvOYu"
      },
      "source": [
        "image,randomNumber, label1, label2 = next(iter(myData_train))\n",
        "image.shape,randomNumber, label1, label2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCjclJNWcXHj"
      },
      "source": [
        "## 6. Creating DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9KjAkdxyO3Z"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\") if use_cuda else torch.device(\"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': 1000}\n",
        "test_kwargs = {'batch_size': 1000}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(myData_train,**train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(myData_test, **test_kwargs)\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(mnist_train,**train_kwargs)\n",
        "# test_loader = torch.utils.data.DataLoader(mnist_test, **test_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpgIDGbPY1TN"
      },
      "source": [
        "# helper function to show an image\n",
        "# (used in the `plot_classes_preds` function below)\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aJSaexhYPZK"
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, randomNumber, labels, sum = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images[0:100,])\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "\n",
        "# write to tensorboard\n",
        "writer.add_image('mnist_images', img_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL08a6IAZCCd"
      },
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNwPHpKncgIT"
      },
      "source": [
        "## 7. Defining Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YrLFurHHd8t"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9226, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.fc3 = nn.Linear(128, 20)\n",
        "\n",
        "    def forward(self, x,y):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.cat((x, y), 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x1 = self.fc2(x)\n",
        "        x2 = self.fc3(x)\n",
        "        output1 = F.log_softmax(x1, dim=1)\n",
        "        output2 = F.log_softmax(x2, dim=1)\n",
        "        return output1, output2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSiegSqjzYyO"
      },
      "source": [
        "model = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVUx3i6EaoKv"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLKHyqhN675A"
      },
      "source": [
        "## 8. Training Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrmujRB20QEx"
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data,randomNumber,target,target1) in enumerate(train_loader):\n",
        "        data,randomNumber,target,target1 = data.to(device), randomNumber.to(device), target.to(device), target1.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, output1 = model(data,randomNumber)\n",
        "        loss = F.nll_loss(output, target) + F.nll_loss(output1, target1) * 2\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        log_interval = 10\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            writer.add_scalar('training loss',\n",
        "                            loss / log_interval,\n",
        "                            epoch * len(train_loader) + batch_idx)\n",
        "\n",
        "\n",
        "def test(model, device, test_loader,epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    with torch.no_grad():\n",
        "        for data,randomNumber,target,target1 in test_loader:\n",
        "            data,randomNumber,target,target1 = data.to(device), randomNumber.to(device), target.to(device), target1.to(device)\n",
        "            output, output1 = model(data,randomNumber)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() + F.nll_loss(output1, target1, reduction='sum').item() * 2  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            pred1 = output1.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            correct1 += pred1.eq(target1.view_as(pred1)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Image Accuracy: {}/{} ({:.0f}%), Sum Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset), correct1, len(test_loader.dataset),\n",
        "        100. * correct1 / len(test_loader.dataset)))\n",
        "    \n",
        "    writer.add_scalar('test loss',\n",
        "                       test_loss,\n",
        "                        epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJW9Kyhkz_I2"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.1,  momentum=0.9)\n",
        "epochs = 20\n",
        "# scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader, epoch)\n",
        "    # scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k_qYE4IaoDW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}